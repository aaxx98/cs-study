# 네트워크

## 시스템 아키텍처 & I/O

### 키워드

**로드 밸런싱(Load Balancing)**
- 둘 이상의 컴퓨터 자원들에게 작업을 나누어 부하를 분산하는 것
- 여러 서버에 네트워크 트래픽이나 작업 부하를 분산시켜 성능과 가용성을 향상시키는 기술

**로드 밸런서**
- 클라이언트와 서버 사이에 위치하여 트래픽을 분산시키는 장치/서비스
- 로드 밸런싱을 수행하는 하드웨어 또는 소프트웨어 장치. 클라이언트 요청을 여러 서버로 분배하는 역할 수행함

**부하(Load)**
- 시스템이나 네트워크에 가해지는 작업량 또는 트래픽의 양 (CPU, 메모리, 네트워크 대역폭 등의 리소스 사용량 등)

**Scale-up**
- 하드웨어 성능을 높여 처리량을 늘림. (수직 확장)
- 기존 서버의 성능을 향상시키는 방법 (CPU, RAM, 디스크 용량 증가 등)

**Scale-out**
- 여러 대의 서버가 나눠서 일하도록 만듦. (수평 확장)
- 서버의 개수를 늘려 부하를 분산시키는 방법. 로드 밸런싱과 함께 사용됨


**로드 밸런서가 서버를 선택하는 방식**
- **라운드 로빈 (Round Robin)**: 서버들에게 순서대로 균등하게 요청을 분배
- **Least Connections**: 현재 연결 개수가 가장 적은 서버를 선택
- **Source (IP Hash)**: 사용자 IP를 해싱하여 분배. (특정 사용자의 동일 서버 연결 보장)

**L4 로드 밸런서**
- IP 주소, 포트번호 기반 분산 (전송 계층)
- TCP/UDP 패킷 정보 확인
- 처리 속도가 빠름

**L7 로드 밸런서**
- HTTP, URL, 쿠키 기반 분산 (응용 계층)
- HTTP 메시지 내용 확인
- 세밀한 제어 가능, SSL 종료 가능

**Active-Standby (주-대기)**
- 주 LB 1대 + 대기 LB 1대
- 구성 단순, 관리 쉬움
- 자동 전환(Failover)
- 대기 서버 유휴 자원, 전환 시 짧은 중단

**Active-Active (이중화)**
- 모든 LB가 동시 처리
- 자원 효율적 활용, 높은 가용성
- 무중단 서비스
- 구성/관리 복잡, 세션 동기화 필요

**Blocking**
- 호출된 함수(B)가 작업을 마칠 때까지 제어권을 가짐 → 호출 함수(A)는 대기
- 작업이 완료될 때까지 프로그램의 실행 흐름이 멈추어 있음

**Non-blocking**
- 호출된 함수(B)가 작업이 끝나지 않아도 제어권을 바로 돌려줌 → 호출 함수(A)는 다른 일 병행 가능
- 작업 완료를 기다리지 않고 즉시 반환하여 다음 작업을 수행할 수 있음

**Synchronous (동기)**
- 호출한 함수(A)가 B의 작업 상태나 결과를 직접 확인
- 작업을 순차적으로 실행하며, 한 작업이 완료되어야 다음 작업이 시작됨

**Asynchronous (비동기)**
- 호출된 함수(B)가 완료 시 Callback이나 이벤트로 A에게 알림
- 작업 완료를 기다리지 않고 다른 작업을 동시에 진행함

**Blocking I/O**
- I/O 요청 시, 작업 완료될 때까지 프로세스가 대기 (Blocking)
- I/O 작업(파일 읽기/쓰기, 네트워크 통신 등)이 완료될 때까지 프로세스나 스레드가 대기하는 방식
- 구현은 단순하지만 리소스 활용도가 낮음
- I/O 동안 CPU 자원 낭비. 다중 클라이언트 환경에서 비효율적
- 동작: 프로세스 I/O 요청 → 커널 데이터 읽는 동안 프로세스 대기 → 커널 데이터 준비 완료 → 프로세스 실행

**Non-Blocking I/O**
- I/O 요청 시, 바로 처리 불가하면 즉시 제어권 반환
- I/O 작업 시 즉시 반환하여 다른 작업을 수행할 수 있는 방식
- 이벤트 루프나 폴링을 통해 작업 완료를 확인하며, 높은 동시성 처리 가능
- 데이터 준비 여부를 주기적으로 확인 (Polling) 필요
- 동작: 프로세스 I/O 요청 → 커널 즉시 "EWOULDBLOCK" 반환 → 프로세스 다른 작업 수행 → 데이터 준비되면 빠르게 복사

**recvfrom**
- 소켓으로부터 데이터를 받는 시스템 호출
- 커널의 recvBuffer → 사용자 프로그램 메모리로 데이터 복사하는 함수

**EWOULDBLOCK**
- Non-blocking 모드에서 아직 읽을 데이터가 없음을 알리는 반환 값
- Non-Blocking 시 데이터가 준비되지 않았음을 알리는 에러 코드

**recvBuffer**
- 커널이 네트워크에서 받은 데이터를 임시 저장하는 커널 버퍼

---
### 질문답

**로드 밸런싱 (Load Balancing)**

***1. 로드 밸런서가 서버를 선택하는 방식 3가지는 각 어떤 상황에 어떤 방식을 사용하는 게 유리한가?***

| 방식 | 동작 원리 | 유리한 상황 |
|------|----------|------------|
| 라운드 로빈 (Round Robin) | 서버에 순서대로 균등 분배 | • 모든 서버 성능이 동일<br>• 요청 처리 시간이 비슷<br>• 간단한 구조의 서비스 |
| 최소 연결 (Least Connection) | 현재 연결 수가 가장 적은 서버로 전달 | • 세션이 길게 유지되는 서비스<br>• 요청 처리 시간이 다를 때<br>• 서버별 부하가 불균등할 때 |
| IP 해시 (IP Hash) | 클라이언트 IP를 해싱하여 특정 서버로 고정 | • 세션 정합성이 중요할 때<br>• 같은 사용자를 같은 서버로 연결<br>• 캐시 효율을 높일 때 |

***2. 로드 밸런서 장애 대비 방식은 어떤 게 있으며 각자 어떤 장단점이 있나?***

| 방식 | 구조 | 장점 | 단점 |
|------|------|------|------|
| Active-Standby (주-대기) | 주 LB 1대 + 대기 LB 1대 | • 구성 단순, 관리 쉬움<br>• 비용 저렴<br>• 자동 전환(Failover) | • 대기 서버 유휴 자원<br>• 전환 시 짧은 중단<br>• 처리 용량 제한 |
| Active-Active (이중화) | 모든 LB가 동시 처리 | • 자원 효율적 활용<br>• 높은 가용성<br>• 무중단 서비스 | • 구성/관리 복잡<br>• 비용 높음<br>• 세션 동기화 필요 |

***3. L4 로드밸런서와 L7 로드밸런서의 차이가 무엇인지?***

| 구분 | L4 (Transport Layer) | L7 (Application Layer) |
|------|---------------------|----------------------|
| 분산 기준 | IP 주소, Port 번호 | HTTP 헤더, URL, 쿠키 등 |
| 확인 정보 | TCP/UDP 패킷 정보 | HTTP 메시지 내용 |
| 처리 속도 | 빠름 | 상대적으로 느림 |
| 기능 | 단순 분산 | 세밀한 제어, SSL 종료 가능 |
| 사용 예시 | IP:Port 기반 분산 | /api/users → 서버 A<br>/images/* → 서버 B |

***4. 로드밸런싱 환경에서 사용자 세션은 어디에 저장해야하는지?***

**중앙 세션 저장소 (Redis, Memcached)**
- 로드밸런싱 환경에서는 Redis나 Memcached 같은 중앙 세션 저장소를 사용하는 것이 가장 권장됨
- 서버 간 독립성을 유지하면서도 모든 서버가 동일한 세션 정보에 접근할 수 있음
- 서버 장애가 발생해도 세션이 유실되지 않으며, Scale-out 시에도 유연하게 대응 가능
- 개별 서버에 세션을 저장하면 같은 사용자가 다른 서버에 연결될 때 로그인 정보가 사라짐

**세션 저장 방식**

- **외부 저장소 사용**
세션 일관성을 위해 세션을 개별 서버가 아닌 DB, Redis, Memcached 등에 저장

- **Sticky Session (세션 고정)**: 같은 사용자는 항상 같은 서버로 연결
  - **한계**:
특정 서버에만 세션이 묶이면 장애나 확장 시 불안정해지므로 대규모 환경에서는 비추천
- **Session Clustering**: 서버 간 세션 정보를 공유
- **외부 세션 스토리지 사용**: Redis, DB 등에 세션 저장 → 가장 많이 사용되는 방식

***5. 티켓 예매 사이트, 공공기관 재난 지원금 신청 등 접속한 사용자에게 대기번호를 부여하는 경우, 로드밸런서와 대기열 시스템의 각 역할은 어떻게 될까?***

**역할 분담**

| 구분 | 역할 | 주요 기능 |
|------|------|----------|
| 1차 로드밸런서 | 대기열 서버로 트래픽 분산 | • 초당 수십만 요청 분산<br>• 대기열 서버 Health Check<br>• 트래픽 균등 분배 |
| 대기열 시스템 | 트래픽 제어 및 순서 관리 | • 대기번호 발급 (Redis 등)<br>• 초당 처리량 제어<br>• 실시간 대기 상태 안내<br>• FIFO 방식 공정성 보장 |
| 2차 로드밸런서 | 실제 서버로 허가된 트래픽만 분산 | • 대기 통과한 사용자만 전달<br>• 서비스 서버 보호<br>• 처리 가능한 만큼만 통과 |

**로드 밸런서**
- 여러 서버나 대기열 서버로 트래픽을 분산시켜 시스템 과부하 방지
- 전체 부하(Load)를 조절하고 네트워크 안정성 유지
- 대기 화면, 대기번호 조회 API 등의 요청 처리
- 실제 서비스 서버로 입장 허가된 사용자 분산

**대기열 시스템**
- 접속한 사용자에게 대기번호 발급 및 요청 순서 관리
- 서버 처리 능력에 맞춰 입장 토큰 발급 (예: 1,000명씩)
- 무거운 작업(DB 조회, 결제 등)에 대한 접근 권한 제어
- 서버 과부하 방지 및 공정한 접속 관리

**확장성 (Scalability)**

***1. Scale-up 대신 Scale-out 방식을 선호하는 이유가 무엇인지?***

| 이유 | 설명 |
|------|------|
| 비용 효율성 | 고성능 서버 1대 비용 > 중급 서버 여러 대 비용 |
| 무중단 확장 | 서버 추가 시 서비스 중단 없음 |
| 고가용성 | 한 대 장애 시 다른 서버들이 처리 |
| 무한 확장 | 이론적으로 무한 확장 가능 |
| 유연성 | 트래픽에 따라 서버 추가/제거 용이 |
| 클라우드 친화적 | Auto Scaling으로 자동 확장 가능 |

- 서버를 여러 대로 나누어 부하를 분산시키기 때문에 한 서버에 과부하가 걸려도 전체 서비스는 안정적으로 운영 가능
- 로드 밸런싱과 결합하면 무중단 확장 가능

**Scale-up (수직 확장)**
- 기존 서버의 CPU, RAM 등 자원을 증가시키는 방식
- 장점: 구성 단순, 즉각적인 성능 향상
- 단점: 비용이 높고 하드웨어 한계가 존재

**Scale-out (수평 확장)**
- 서버의 개수를 늘려 부하를 분산시키는 방식
- 장점: 유연한 확장, 장애 대응력 높음
- 단점: 서버 간 데이터 일관성 관리 필요, 네트워크 부하 증가, 관리 복잡성 상승

***2. Scale-out 방법으로 서버를 계속 늘리면 문제가 생기지 않는지?***

**문제 영역 및 해결책**

| 문제 영역 | 내용 | 해결책 |
|----------|------|--------|
| DB 병목 | • DB는 1대인데 서버만 증가<br>• DB가 단일 장애점 | DB Replication, Sharding, Read Replica |
| 네트워크 오버헤드 | • 서버 간 통신 증가<br>• 대역폭 한계 | 캐싱, 비동기 처리, 메시지 큐 |
| 세션/상태 관리 | • 서버마다 다른 상태 | Redis 중앙 저장소 |
| 관리 복잡도 | • 모니터링, 배포 어려움 | Kubernetes, Docker 오케스트레이션 |
| 로드밸런서 한계 | • LB 자체가 병목 | L4/L7 분리, DNS 분산 |
| 비용 증가 | • 일정 규모 이상 비효율 | 캐싱, CDN, 코드 최적화 |

**발생 가능한 문제**
- 서버 간 데이터 일관성 유지가 어려움
- 세션 관리 복잡도 증가
- 네트워크 부하 및 관리 비용 상승

**해결 방법**
- 중앙 세션 관리(예: Redis)
- 분산 캐시 시스템 도입
- 마이크로서비스 아키텍처(MSA) 적용

**결론**: 단순히 서버만 늘리는 것이 아닌 아키텍처 개선 + 최적화를 병행해야 함

**Blocking/Non-blocking & Synchronous/Asynchronous**

***1. Blocking/Non-blocking과 Synchronous/Asynchronous의 차이는?***

| 구분 | Blocking/Non-blocking | Synchronous/Asynchronous |
|------|---------------------|------------------------|
| 관점 | 제어권 관점 | 작업 완료 관심 관점 |
| 핵심 | 제어권을 언제 반환하는가 | 작업 완료를 누가 신경쓰는가 |

**4가지 조합**

| 조합 | 설명 | 사용 사례 |
|------|------|----------|
| Blocking + Synchronous | 가장 일반적, 순차 실행 | 일반적인 함수 호출 |
| Blocking + Asynchronous | 비효율적 | 거의 사용 안 함 |
| Non-blocking + Synchronous | 폴링(Polling) 방식 | 상태를 주기적으로 체크 |
| Non-blocking + Asynchronous | 가장 효율적, 성능 최적 | Node.js, 비동기 I/O |

**Blocking I/O & Non-Blocking I/O**

***1. Blocking I/O와 Non-Blocking I/O의 동작 차이는?***

**Blocking I/O 동작**
- 단계:
    1. User Process가 recvfrom() 호출
    2. 커널이 데이터 준비될 때까지 대기 (Block)
    3. 데이터가 준비되면 User Process에 복사
    4. 작업 완료 후 제어권 반환
- 문제점: 여러 Client 접속 시 각 Client마다 별도 Thread 필요 → Thread 증가 → 컨텍스트 스위칭 증가 → 비효율

**Non-Blocking I/O 동작**
- 단계:
    1. User Process가 recvfrom() 호출
    2. 커널이 즉시 "EWOULDBLOCK" 반환
    3. User Process는 다른 작업 수행 가능
    4. 데이터 준비 완료 시 다시 호출하여 수신
- 장점: I/O 작업 중에도 다른 작업 진행 가능 → Thread 개수 최소화 → 효율적인 리소스 사용

**비교표**

| 구분 | Blocking I/O | Non-Blocking I/O |
|------|-------------|------------------|
| 제어권 반환 | I/O 완료 후 | 즉시 반환 |
| 프로세스 상태 | 대기(정지) | 실행 가능 |
| CPU 활용 | 낮음 | 높음 |
| 구현 난이도 | 쉬움 | 복잡함 |
| 다중 클라이언트 | 스레드 증가 | 효율적 (이벤트 기반 가능) |

